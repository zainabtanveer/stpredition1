{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMrmzLK6F802keNz/tZESOn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zainabtanveer/stpredition1/blob/master/Copy_of_Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaE1NaxIuGu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "39afc4cc-0d90-4629-c4fe-ab9c70e1912d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbJMz801wSmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0ecca87f-bd8f-4534-da06-c0d83c13623f"
      },
      "source": [
        "!pip install yahoo-fin\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yahoo-fin\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/5c/6bf0c0147cc94d643e2a2413d0a9b27967e964ee99f88f26db93a0b963b8/yahoo_fin-0.8.6-py3-none-any.whl\n",
            "Installing collected packages: yahoo-fin\n",
            "Successfully installed yahoo-fin-0.8.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzqYpdddxBco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "c3a58657-691d-46af-8cbf-ad162375b7b9"
      },
      "source": [
        "!pip install requests_html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting requests_html\n",
            "  Downloading https://files.pythonhosted.org/packages/24/bc/a4380f09bab3a776182578ce6b2771e57259d0d4dbce178205779abdc347/requests_html-0.10.0-py3-none-any.whl\n",
            "Collecting pyquery\n",
            "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
            "Collecting fake-useragent\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/79/af647635d6968e2deb57a208d309f6069d31cb138066d7e821e575112a80/fake-useragent-0.1.11.tar.gz\n",
            "Collecting parse\n",
            "  Downloading https://files.pythonhosted.org/packages/22/35/930b6d670cac8ead61dfc05f0e62994ab0697573de17a3231d65631f16d5/parse-1.16.0.tar.gz\n",
            "Collecting w3lib\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/59/b6b14521090e7f42669cafdb84b0ab89301a42f1f1a82fcf5856661ea3a7/w3lib-1.22.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from requests_html) (0.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from requests_html) (2.23.0)\n",
            "Collecting pyppeteer>=0.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/4b/3c2aabdd1b91fa52aa9de6cde33b488b0592b4d48efb0ad9efbf71c49f5b/pyppeteer-0.2.2-py3-none-any.whl (145kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.6/dist-packages (from pyquery->requests_html) (4.2.6)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from w3lib->requests_html) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->requests_html) (4.6.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (2020.6.20)\n",
            "Collecting tqdm<5.0.0,>=4.42.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/88/7b0ea5fa8192d1733dea459a9e3059afc87819cb4072c43263f2ec7ab768/tqdm-4.48.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.8MB/s \n",
            "\u001b[?25hCollecting websockets<9.0,>=8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.6MB/s \n",
            "\u001b[?25hCollecting pyee<8.0.0,>=7.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/28/1cedd44c27907f1507a28ff2d36fc6cdb981c9deff2fa288bc48a700c7c9/pyee-7.0.2-py2.py3-none-any.whl\n",
            "Collecting appdirs<2.0.0,>=1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: fake-useragent, parse\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-cp36-none-any.whl size=13484 sha256=93b98997f53e86da98c975e388ab3c0e8eff9b785667ab313fa501aa8dfd2127\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/63/09/d1dc15179f175357d3f5c00cbffbac37f9e8690d80545143ff\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.16.0-cp36-none-any.whl size=23996 sha256=3382a44017afe4b6bc662b2cab3f372b756062c4e3de53ec1eb7b845c03d7eeb\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ca/7d/4e6d687c81f1110b47140845d6dce4e6d7cdae0996caeca560\n",
            "Successfully built fake-useragent parse\n",
            "\u001b[31mERROR: pyppeteer 0.2.2 has requirement urllib3<2.0.0,>=1.25.8, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: cssselect, pyquery, fake-useragent, parse, w3lib, tqdm, websockets, pyee, appdirs, pyppeteer, requests-html\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed appdirs-1.4.4 cssselect-1.1.0 fake-useragent-0.1.11 parse-1.16.0 pyee-7.0.2 pyppeteer-0.2.2 pyquery-1.4.1 requests-html-0.10.0 tqdm-4.48.0 w3lib-1.22.0 websockets-8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU4EnpfnxqxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slz68-kLxx37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set seed, so we can get the same results after rerunning several times\n",
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCnj09Xjx56y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, \n",
        "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "    # see if ticker is already a loaded stock from yahoo finance\n",
        "    if isinstance(ticker, str):\n",
        "        # load it from yahoo_fin library\n",
        "        df = si.get_data(ticker)\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "        # already loaded, use it directly\n",
        "        df = ticker\n",
        "    # this will contain all the elements we want to return from this function\n",
        "    result = {}\n",
        "    # we will also return the original dataframe itself\n",
        "    result['df'] = df.copy()\n",
        "    # make sure that the passed feature_columns exist in the dataframe\n",
        "    for col in feature_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "    if scale:\n",
        "        column_scaler = {}\n",
        "        # scale the data (prices) from 0 to 1\n",
        "        for column in feature_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "            column_scaler[column] = scaler\n",
        "\n",
        "        # add the MinMaxScaler instances to the result returned\n",
        "        result[\"column_scaler\"] = column_scaler\n",
        "    # add the target column (label) by shifting by `lookup_step`\n",
        "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
        "    # last `lookup_step` columns contains NaN in future column\n",
        "    # get them before droping NaNs\n",
        "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
        "    # drop NaNs\n",
        "    df.dropna(inplace=True)\n",
        "    sequence_data = []\n",
        "    sequences = deque(maxlen=n_steps)\n",
        "    for entry, target in zip(df[feature_columns].values, df['future'].values):\n",
        "        sequences.append(entry)\n",
        "        if len(sequences) == n_steps:\n",
        "            sequence_data.append([np.array(sequences), target])\n",
        "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
        "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 59 (that is 50+10-1) length\n",
        "    # this last_sequence will be used to predict in future dates that are not available in the dataset\n",
        "    last_sequence = list(sequences) + list(last_sequence)\n",
        "    # shift the last sequence by -1\n",
        "    last_sequence = np.array(pd.DataFrame(last_sequence).shift(-1).dropna())\n",
        "    # add to result\n",
        "    result['last_sequence'] = last_sequence\n",
        "    # construct the X's and y's\n",
        "    X, y = [], []\n",
        "    for seq, target in sequence_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "    # convert to numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    # reshape X to fit the neural network\n",
        "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
        "    # split the dataset\n",
        "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
        "    # return the result\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JcTtrTgxJJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
        "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            # first layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
        "        elif i == n_layers - 1:\n",
        "            # last layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "            # hidden layers\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True))\n",
        "        # add dropout after each layer\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2PSoj_oyckh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Window size or the sequence length\n",
        "N_STEPS = 100\n",
        "# Lookup step, 1 is the next day\n",
        "LOOKUP_STEP = 1\n",
        "# test ratio size, 0.2 is 20%\n",
        "TEST_SIZE = 0.2\n",
        "# features to use\n",
        "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
        "# date now\n",
        "date_now = time.strftime(\"%Y-%m-%d\")\n",
        "### model parameters\n",
        "N_LAYERS = 3\n",
        "# LSTM cell\n",
        "CELL = LSTM\n",
        "# 256 LSTM neurons\n",
        "UNITS = 256\n",
        "# 40% dropout\n",
        "DROPOUT = 0.4\n",
        "# whether to use bidirectional RNNs\n",
        "BIDIRECTIONAL = False\n",
        "### training parameters\n",
        "# mean absolute error loss\n",
        "# LOSS = \"mae\"\n",
        "# huber loss\n",
        "LOSS = \"huber_loss\"\n",
        "OPTIMIZER = \"adam\"\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 500\n",
        "# Apple stock market\n",
        "ticker = \"AAPL\"\n",
        "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
        "# model name to save, making it as unique as possible based on parameters\n",
        "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
        "if BIDIRECTIONAL:\n",
        "    model_name += \"-b\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xidCh9nFypcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create these folders if they does not exist\n",
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "if not os.path.isdir(\"logs\"):\n",
        "    os.mkdir(\"logs\")\n",
        "if not os.path.isdir(\"data\"):\n",
        "    os.mkdir(\"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuRzHsSMy1RV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "ee9f037a-a10f-4e01-be93-dae885439c07"
      },
      "source": [
        "# load the data\n",
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
        "\n",
        "# save the dataframe\n",
        "data[\"df\"].to_csv(ticker_data_filename)\n",
        "\n",
        "# construct the model\n",
        "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "# some tensorflow callbacks\n",
        "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "\n",
        "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                    callbacks=[checkpointer, tensorboard],\n",
        "                    verbose=1)\n",
        "\n",
        "model.save(os.path.join(\"results\", model_name) + \".h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6370e-04 - mean_absolute_error: 0.0180\n",
            "Epoch 00001: val_loss improved from inf to 0.00028, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 16s 128ms/step - loss: 8.6370e-04 - mean_absolute_error: 0.0180 - val_loss: 2.8435e-04 - val_mean_absolute_error: 0.0102\n",
            "Epoch 2/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.2842e-04 - mean_absolute_error: 0.0165\n",
            "Epoch 00002: val_loss did not improve from 0.00028\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 6.2842e-04 - mean_absolute_error: 0.0165 - val_loss: 4.8274e-04 - val_mean_absolute_error: 0.0139\n",
            "Epoch 3/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 5.2018e-04 - mean_absolute_error: 0.0147\n",
            "Epoch 00003: val_loss did not improve from 0.00028\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 5.2018e-04 - mean_absolute_error: 0.0147 - val_loss: 4.1402e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 4/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 4.0855e-04 - mean_absolute_error: 0.0131\n",
            "Epoch 00004: val_loss improved from 0.00028 to 0.00019, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 4.0855e-04 - mean_absolute_error: 0.0131 - val_loss: 1.9169e-04 - val_mean_absolute_error: 0.0074\n",
            "Epoch 5/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 4.1973e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 00005: val_loss did not improve from 0.00019\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 4.1973e-04 - mean_absolute_error: 0.0135 - val_loss: 2.3313e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 6/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 3.2443e-04 - mean_absolute_error: 0.0120\n",
            "Epoch 00006: val_loss did not improve from 0.00019\n",
            "124/124 [==============================] - 16s 128ms/step - loss: 3.2443e-04 - mean_absolute_error: 0.0120 - val_loss: 3.3335e-04 - val_mean_absolute_error: 0.0123\n",
            "Epoch 7/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 4.1145e-04 - mean_absolute_error: 0.0136\n",
            "Epoch 00007: val_loss improved from 0.00019 to 0.00018, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 124ms/step - loss: 4.1145e-04 - mean_absolute_error: 0.0136 - val_loss: 1.7594e-04 - val_mean_absolute_error: 0.0074\n",
            "Epoch 8/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 3.4599e-04 - mean_absolute_error: 0.0125\n",
            "Epoch 00008: val_loss did not improve from 0.00018\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 3.4599e-04 - mean_absolute_error: 0.0125 - val_loss: 4.2831e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 9/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 3.6564e-04 - mean_absolute_error: 0.0130\n",
            "Epoch 00009: val_loss improved from 0.00018 to 0.00009, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 121ms/step - loss: 3.6564e-04 - mean_absolute_error: 0.0130 - val_loss: 8.6924e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 10/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 2.3806e-04 - mean_absolute_error: 0.0109\n",
            "Epoch 00010: val_loss did not improve from 0.00009\n",
            "124/124 [==============================] - 15s 121ms/step - loss: 2.3806e-04 - mean_absolute_error: 0.0109 - val_loss: 1.5018e-04 - val_mean_absolute_error: 0.0083\n",
            "Epoch 11/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 2.8891e-04 - mean_absolute_error: 0.0121\n",
            "Epoch 00011: val_loss improved from 0.00009 to 0.00008, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 120ms/step - loss: 2.8891e-04 - mean_absolute_error: 0.0121 - val_loss: 7.7499e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 12/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 2.1708e-04 - mean_absolute_error: 0.0107\n",
            "Epoch 00012: val_loss improved from 0.00008 to 0.00007, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 2.1708e-04 - mean_absolute_error: 0.0107 - val_loss: 6.8716e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 13/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 2.2004e-04 - mean_absolute_error: 0.0107\n",
            "Epoch 00013: val_loss improved from 0.00007 to 0.00005, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 2.2004e-04 - mean_absolute_error: 0.0107 - val_loss: 4.5331e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 14/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 2.3299e-04 - mean_absolute_error: 0.0111\n",
            "Epoch 00014: val_loss did not improve from 0.00005\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 2.3299e-04 - mean_absolute_error: 0.0111 - val_loss: 7.9058e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 15/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.8712e-04 - mean_absolute_error: 0.0100\n",
            "Epoch 00015: val_loss did not improve from 0.00005\n",
            "124/124 [==============================] - 15s 120ms/step - loss: 1.8712e-04 - mean_absolute_error: 0.0100 - val_loss: 7.8476e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 16/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.6247e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 00016: val_loss did not improve from 0.00005\n",
            "124/124 [==============================] - 15s 124ms/step - loss: 1.6247e-04 - mean_absolute_error: 0.0098 - val_loss: 7.0690e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 17/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.6205e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 00017: val_loss did not improve from 0.00005\n",
            "124/124 [==============================] - 15s 121ms/step - loss: 1.6205e-04 - mean_absolute_error: 0.0098 - val_loss: 5.5119e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 18/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.5005e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00018: val_loss improved from 0.00005 to 0.00003, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 123ms/step - loss: 1.5005e-04 - mean_absolute_error: 0.0096 - val_loss: 2.6673e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 19/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.5917e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00019: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 15s 121ms/step - loss: 1.5917e-04 - mean_absolute_error: 0.0096 - val_loss: 5.9000e-05 - val_mean_absolute_error: 0.0073\n",
            "Epoch 20/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.7960e-04 - mean_absolute_error: 0.0104\n",
            "Epoch 00020: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 15s 121ms/step - loss: 1.7960e-04 - mean_absolute_error: 0.0104 - val_loss: 4.3073e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 21/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.7226e-04 - mean_absolute_error: 0.0104\n",
            "Epoch 00021: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 1.7226e-04 - mean_absolute_error: 0.0104 - val_loss: 1.7637e-04 - val_mean_absolute_error: 0.0133\n",
            "Epoch 22/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.4518e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 00022: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 1.4518e-04 - mean_absolute_error: 0.0094 - val_loss: 1.0504e-04 - val_mean_absolute_error: 0.0090\n",
            "Epoch 23/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3523e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00023: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.3523e-04 - mean_absolute_error: 0.0092 - val_loss: 6.4516e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 24/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.4850e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00024: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.4850e-04 - mean_absolute_error: 0.0093 - val_loss: 6.6770e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 25/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2722e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00025: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 15s 121ms/step - loss: 1.2722e-04 - mean_absolute_error: 0.0090 - val_loss: 4.2072e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 26/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3813e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00026: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 1.3813e-04 - mean_absolute_error: 0.0093 - val_loss: 3.7606e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 27/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3511e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00027: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 15s 123ms/step - loss: 1.3511e-04 - mean_absolute_error: 0.0092 - val_loss: 4.8798e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 28/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2684e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00028: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 16s 128ms/step - loss: 1.2684e-04 - mean_absolute_error: 0.0091 - val_loss: 3.8090e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 29/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.4980e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 00029: val_loss did not improve from 0.00003\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 1.4980e-04 - mean_absolute_error: 0.0098 - val_loss: 1.1889e-04 - val_mean_absolute_error: 0.0075\n",
            "Epoch 30/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3989e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00030: val_loss improved from 0.00003 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.3989e-04 - mean_absolute_error: 0.0093 - val_loss: 1.9942e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 31/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.4281e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 00031: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.4281e-04 - mean_absolute_error: 0.0094 - val_loss: 2.2878e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 32/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.5613e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 00032: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.5613e-04 - mean_absolute_error: 0.0099 - val_loss: 2.8238e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 33/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.5514e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 00033: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.5514e-04 - mean_absolute_error: 0.0101 - val_loss: 6.3156e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 34/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.4829e-04 - mean_absolute_error: 0.0104\n",
            "Epoch 00034: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.4829e-04 - mean_absolute_error: 0.0104 - val_loss: 5.9442e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 35/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.4600e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00035: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.4600e-04 - mean_absolute_error: 0.0096 - val_loss: 2.9774e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 36/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3075e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00036: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 1.3075e-04 - mean_absolute_error: 0.0092 - val_loss: 1.1496e-04 - val_mean_absolute_error: 0.0084\n",
            "Epoch 37/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3158e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00037: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 120ms/step - loss: 1.3158e-04 - mean_absolute_error: 0.0093 - val_loss: 4.9917e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 38/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.5145e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 00038: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.5145e-04 - mean_absolute_error: 0.0101 - val_loss: 5.9512e-05 - val_mean_absolute_error: 0.0084\n",
            "Epoch 39/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.6648e-04 - mean_absolute_error: 0.0105\n",
            "Epoch 00039: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.6648e-04 - mean_absolute_error: 0.0105 - val_loss: 5.3332e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 40/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3668e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 00040: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.3668e-04 - mean_absolute_error: 0.0095 - val_loss: 4.0995e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 41/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3871e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 00041: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.3871e-04 - mean_absolute_error: 0.0095 - val_loss: 3.0882e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 42/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3868e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 00042: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.3868e-04 - mean_absolute_error: 0.0095 - val_loss: 1.3781e-04 - val_mean_absolute_error: 0.0123\n",
            "Epoch 43/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3912e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 00043: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.3912e-04 - mean_absolute_error: 0.0094 - val_loss: 3.4364e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 44/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1820e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00044: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.1820e-04 - mean_absolute_error: 0.0088 - val_loss: 4.4388e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 45/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2226e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00045: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.2226e-04 - mean_absolute_error: 0.0089 - val_loss: 6.8043e-05 - val_mean_absolute_error: 0.0090\n",
            "Epoch 46/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3084e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00046: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 120ms/step - loss: 1.3084e-04 - mean_absolute_error: 0.0093 - val_loss: 7.0646e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 47/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1569e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00047: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 121ms/step - loss: 1.1569e-04 - mean_absolute_error: 0.0088 - val_loss: 5.8044e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 48/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3320e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 00048: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.3320e-04 - mean_absolute_error: 0.0098 - val_loss: 4.0753e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 49/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1641e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00049: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 16s 126ms/step - loss: 1.1641e-04 - mean_absolute_error: 0.0090 - val_loss: 2.8535e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 50/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3222e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00050: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.3222e-04 - mean_absolute_error: 0.0093 - val_loss: 4.1063e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 51/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1842e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00051: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.1842e-04 - mean_absolute_error: 0.0089 - val_loss: 5.5392e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 52/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2263e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00052: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.2263e-04 - mean_absolute_error: 0.0090 - val_loss: 4.3313e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 53/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0717e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00053: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0717e-04 - mean_absolute_error: 0.0086 - val_loss: 4.0067e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 54/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0507e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00054: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.0507e-04 - mean_absolute_error: 0.0084 - val_loss: 1.9274e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 55/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2406e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00055: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.2406e-04 - mean_absolute_error: 0.0089 - val_loss: 5.0757e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 56/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1766e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00056: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.1766e-04 - mean_absolute_error: 0.0091 - val_loss: 5.5921e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 57/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2830e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00057: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 120ms/step - loss: 1.2830e-04 - mean_absolute_error: 0.0093 - val_loss: 2.3707e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 58/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0868e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00058: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.0868e-04 - mean_absolute_error: 0.0087 - val_loss: 2.7941e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 59/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2533e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00059: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.2533e-04 - mean_absolute_error: 0.0093 - val_loss: 3.0893e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 60/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0330e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00060: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.0330e-04 - mean_absolute_error: 0.0082 - val_loss: 2.7699e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 61/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.9926e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00061: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 9.9926e-05 - mean_absolute_error: 0.0081 - val_loss: 3.3574e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 62/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1494e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00062: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.1494e-04 - mean_absolute_error: 0.0088 - val_loss: 3.1087e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 63/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0946e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00063: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.0946e-04 - mean_absolute_error: 0.0084 - val_loss: 5.1486e-05 - val_mean_absolute_error: 0.0073\n",
            "Epoch 64/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0740e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00064: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.0740e-04 - mean_absolute_error: 0.0087 - val_loss: 3.7933e-05 - val_mean_absolute_error: 0.0067\n",
            "Epoch 65/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.6737e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 00065: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.6737e-05 - mean_absolute_error: 0.0082 - val_loss: 2.2425e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 66/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0283e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00066: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 1.0283e-04 - mean_absolute_error: 0.0083 - val_loss: 4.4362e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 67/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1063e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00067: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.1063e-04 - mean_absolute_error: 0.0086 - val_loss: 2.4049e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 68/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2515e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00068: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.2515e-04 - mean_absolute_error: 0.0093 - val_loss: 4.9961e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 69/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1939e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00069: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.1939e-04 - mean_absolute_error: 0.0090 - val_loss: 2.3383e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 70/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3636e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 00070: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.3636e-04 - mean_absolute_error: 0.0098 - val_loss: 4.3280e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 71/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.3158e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00071: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 9.3158e-05 - mean_absolute_error: 0.0079 - val_loss: 3.0715e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 72/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0249e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00072: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0249e-04 - mean_absolute_error: 0.0082 - val_loss: 2.1466e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 73/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.9870e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00073: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 9.9870e-05 - mean_absolute_error: 0.0080 - val_loss: 3.8132e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 74/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2418e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00074: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 1.2418e-04 - mean_absolute_error: 0.0092 - val_loss: 6.7235e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 75/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2400e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00075: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.2400e-04 - mean_absolute_error: 0.0091 - val_loss: 8.0928e-05 - val_mean_absolute_error: 0.0079\n",
            "Epoch 76/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.3220e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 00076: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.3220e-04 - mean_absolute_error: 0.0094 - val_loss: 9.4170e-05 - val_mean_absolute_error: 0.0099\n",
            "Epoch 77/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1606e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00077: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.1606e-04 - mean_absolute_error: 0.0089 - val_loss: 8.9453e-05 - val_mean_absolute_error: 0.0079\n",
            "Epoch 78/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1535e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00078: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.1535e-04 - mean_absolute_error: 0.0089 - val_loss: 2.7958e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 79/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1425e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00079: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.1425e-04 - mean_absolute_error: 0.0086 - val_loss: 3.3119e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 80/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0366e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00080: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.0366e-04 - mean_absolute_error: 0.0083 - val_loss: 8.7149e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 81/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1330e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00081: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 1.1330e-04 - mean_absolute_error: 0.0087 - val_loss: 6.5648e-05 - val_mean_absolute_error: 0.0069\n",
            "Epoch 82/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.5835e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00082: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.5835e-05 - mean_absolute_error: 0.0080 - val_loss: 4.4350e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 83/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.8611e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00083: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.8611e-05 - mean_absolute_error: 0.0080 - val_loss: 2.8994e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 84/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1372e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00084: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.1372e-04 - mean_absolute_error: 0.0085 - val_loss: 2.9922e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 85/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0615e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00085: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.0615e-04 - mean_absolute_error: 0.0084 - val_loss: 2.9726e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 86/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0349e-04 - mean_absolute_error: 0.0081\n",
            "Epoch 00086: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.0349e-04 - mean_absolute_error: 0.0081 - val_loss: 2.3036e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 87/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.6813e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00087: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 9.6813e-05 - mean_absolute_error: 0.0081 - val_loss: 1.2876e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 88/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1057e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00088: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.1057e-04 - mean_absolute_error: 0.0087 - val_loss: 5.9197e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 89/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2592e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00089: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.2592e-04 - mean_absolute_error: 0.0089 - val_loss: 4.5480e-05 - val_mean_absolute_error: 0.0067\n",
            "Epoch 90/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1690e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00090: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.1690e-04 - mean_absolute_error: 0.0089 - val_loss: 1.7622e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 91/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0781e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00091: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0781e-04 - mean_absolute_error: 0.0086 - val_loss: 1.8627e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 92/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.7507e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 00092: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 124ms/step - loss: 9.7507e-05 - mean_absolute_error: 0.0084 - val_loss: 1.8912e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 93/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0298e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00093: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 120ms/step - loss: 1.0298e-04 - mean_absolute_error: 0.0083 - val_loss: 4.3748e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 94/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0533e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00094: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0533e-04 - mean_absolute_error: 0.0084 - val_loss: 1.8853e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 95/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0594e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00095: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.0594e-04 - mean_absolute_error: 0.0083 - val_loss: 3.7263e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 96/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2041e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00096: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 1.2041e-04 - mean_absolute_error: 0.0088 - val_loss: 2.2670e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 97/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0442e-04 - mean_absolute_error: 0.0081\n",
            "Epoch 00097: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.0442e-04 - mean_absolute_error: 0.0081 - val_loss: 2.4567e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 98/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0050e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00098: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.0050e-04 - mean_absolute_error: 0.0083 - val_loss: 4.6961e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 99/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0070e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00099: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.0070e-04 - mean_absolute_error: 0.0082 - val_loss: 5.0700e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 100/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1967e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00100: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 122ms/step - loss: 1.1967e-04 - mean_absolute_error: 0.0090 - val_loss: 3.7484e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 101/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.7024e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00101: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 9.7024e-05 - mean_absolute_error: 0.0079 - val_loss: 2.0511e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 102/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0346e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00102: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.0346e-04 - mean_absolute_error: 0.0083 - val_loss: 3.2425e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 103/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0805e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00103: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.0805e-04 - mean_absolute_error: 0.0082 - val_loss: 3.4749e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 104/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0203e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00104: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.0203e-04 - mean_absolute_error: 0.0083 - val_loss: 3.2654e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 105/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1456e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00105: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.1456e-04 - mean_absolute_error: 0.0091 - val_loss: 2.9656e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 106/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.0706e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00106: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.0706e-05 - mean_absolute_error: 0.0079 - val_loss: 3.1609e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 107/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.5377e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00107: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.5377e-05 - mean_absolute_error: 0.0078 - val_loss: 8.2825e-05 - val_mean_absolute_error: 0.0083\n",
            "Epoch 108/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0393e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00108: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.0393e-04 - mean_absolute_error: 0.0083 - val_loss: 3.9399e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 109/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0075e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00109: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.0075e-04 - mean_absolute_error: 0.0083 - val_loss: 2.9837e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 110/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.9763e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 00110: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 9.9763e-05 - mean_absolute_error: 0.0083 - val_loss: 3.4969e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 111/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0749e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00111: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.0749e-04 - mean_absolute_error: 0.0087 - val_loss: 4.1497e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 112/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0252e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00112: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.0252e-04 - mean_absolute_error: 0.0084 - val_loss: 3.2630e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 113/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.5322e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00113: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 9.5322e-05 - mean_absolute_error: 0.0081 - val_loss: 5.0812e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 114/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2175e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00114: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 16s 128ms/step - loss: 1.2175e-04 - mean_absolute_error: 0.0091 - val_loss: 6.6646e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 115/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.6236e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00115: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 16s 127ms/step - loss: 9.6236e-05 - mean_absolute_error: 0.0081 - val_loss: 7.2102e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 116/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0069e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00116: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 1.0069e-04 - mean_absolute_error: 0.0082 - val_loss: 2.9712e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 117/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.9189e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00117: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 9.9189e-05 - mean_absolute_error: 0.0081 - val_loss: 2.4012e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 118/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0507e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00118: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 1.0507e-04 - mean_absolute_error: 0.0083 - val_loss: 4.3960e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 119/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.5816e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00119: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 9.5816e-05 - mean_absolute_error: 0.0081 - val_loss: 2.4109e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 120/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6636e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00120: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 123ms/step - loss: 8.6636e-05 - mean_absolute_error: 0.0076 - val_loss: 3.6964e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 121/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0491e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00121: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 1.0491e-04 - mean_absolute_error: 0.0085 - val_loss: 3.7629e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 122/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.6749e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 00122: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 9.6749e-05 - mean_absolute_error: 0.0084 - val_loss: 1.7522e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 123/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.4814e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00123: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 9.4814e-05 - mean_absolute_error: 0.0079 - val_loss: 3.6698e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 124/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1865e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00124: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.1865e-04 - mean_absolute_error: 0.0089 - val_loss: 3.3461e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 125/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0903e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00125: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.0903e-04 - mean_absolute_error: 0.0086 - val_loss: 2.5870e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 126/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.9206e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00126: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 8.9206e-05 - mean_absolute_error: 0.0077 - val_loss: 2.4146e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 127/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0325e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00127: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.0325e-04 - mean_absolute_error: 0.0086 - val_loss: 2.0851e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 128/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.9646e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00128: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 9.9646e-05 - mean_absolute_error: 0.0081 - val_loss: 6.5836e-05 - val_mean_absolute_error: 0.0075\n",
            "Epoch 129/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.8390e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00129: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 9.8390e-05 - mean_absolute_error: 0.0081 - val_loss: 4.8475e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 130/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.5817e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00130: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 9.5817e-05 - mean_absolute_error: 0.0081 - val_loss: 2.7042e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 131/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6525e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00131: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 8.6525e-05 - mean_absolute_error: 0.0077 - val_loss: 3.2133e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 132/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.5396e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00132: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 120ms/step - loss: 9.5396e-05 - mean_absolute_error: 0.0081 - val_loss: 4.8235e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 133/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.8152e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00133: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 9.8152e-05 - mean_absolute_error: 0.0080 - val_loss: 2.4469e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 134/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0357e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00134: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 1.0357e-04 - mean_absolute_error: 0.0082 - val_loss: 6.9598e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 135/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.1019e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00135: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 1.1019e-04 - mean_absolute_error: 0.0088 - val_loss: 2.9508e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 136/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.9832e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00136: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 16s 129ms/step - loss: 9.9832e-05 - mean_absolute_error: 0.0081 - val_loss: 5.7695e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 137/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.4990e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00137: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 8.4990e-05 - mean_absolute_error: 0.0078 - val_loss: 1.6774e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 138/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.3261e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00138: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 9.3261e-05 - mean_absolute_error: 0.0079 - val_loss: 6.1406e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 139/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.4634e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00139: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 9.4634e-05 - mean_absolute_error: 0.0079 - val_loss: 3.1919e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 140/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0137e-04 - mean_absolute_error: 0.0081\n",
            "Epoch 00140: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.0137e-04 - mean_absolute_error: 0.0081 - val_loss: 2.3921e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 141/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0364e-04 - mean_absolute_error: 0.0081\n",
            "Epoch 00141: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 122ms/step - loss: 1.0364e-04 - mean_absolute_error: 0.0081 - val_loss: 7.5556e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 142/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.4827e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00142: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.4827e-05 - mean_absolute_error: 0.0079 - val_loss: 5.6849e-05 - val_mean_absolute_error: 0.0088\n",
            "Epoch 143/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0775e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00143: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 1.0775e-04 - mean_absolute_error: 0.0086 - val_loss: 2.0420e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 144/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.9304e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00144: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 8.9304e-05 - mean_absolute_error: 0.0077 - val_loss: 2.5699e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 145/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.2072e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00145: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.2072e-04 - mean_absolute_error: 0.0089 - val_loss: 4.2931e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 146/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0034e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00146: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 1.0034e-04 - mean_absolute_error: 0.0082 - val_loss: 2.8401e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 147/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.0206e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00147: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 9.0206e-05 - mean_absolute_error: 0.0078 - val_loss: 2.6470e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 148/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.1236e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00148: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.1236e-05 - mean_absolute_error: 0.0074 - val_loss: 2.4433e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 149/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.5963e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00149: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 9.5963e-05 - mean_absolute_error: 0.0079 - val_loss: 6.4958e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 150/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0026e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00150: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0026e-04 - mean_absolute_error: 0.0083 - val_loss: 2.0964e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 151/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.9052e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00151: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 8.9052e-05 - mean_absolute_error: 0.0078 - val_loss: 2.6375e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 152/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9801e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00152: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.9801e-05 - mean_absolute_error: 0.0074 - val_loss: 2.6255e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 153/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.5642e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00153: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.5642e-05 - mean_absolute_error: 0.0077 - val_loss: 3.5687e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 154/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0230e-04 - mean_absolute_error: 0.0081\n",
            "Epoch 00154: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0230e-04 - mean_absolute_error: 0.0081 - val_loss: 4.0486e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 155/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.2406e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00155: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.2406e-05 - mean_absolute_error: 0.0078 - val_loss: 8.1677e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 156/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.8372e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00156: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.8372e-05 - mean_absolute_error: 0.0081 - val_loss: 3.5557e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 157/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.8921e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00157: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 122ms/step - loss: 8.8921e-05 - mean_absolute_error: 0.0077 - val_loss: 1.6295e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 158/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.3408e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00158: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.3408e-05 - mean_absolute_error: 0.0075 - val_loss: 2.6563e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 159/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0150e-04 - mean_absolute_error: 0.0081\n",
            "Epoch 00159: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0150e-04 - mean_absolute_error: 0.0081 - val_loss: 6.0645e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 160/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.3712e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00160: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 9.3712e-05 - mean_absolute_error: 0.0078 - val_loss: 3.0547e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 161/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0928e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00161: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0928e-04 - mean_absolute_error: 0.0083 - val_loss: 1.9344e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 162/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.9033e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00162: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 9.9033e-05 - mean_absolute_error: 0.0080 - val_loss: 1.8514e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 163/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7609e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00163: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 8.7609e-05 - mean_absolute_error: 0.0077 - val_loss: 2.3234e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 164/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0245e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00164: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0245e-04 - mean_absolute_error: 0.0082 - val_loss: 1.5609e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 165/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.3012e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00165: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 9.3012e-05 - mean_absolute_error: 0.0079 - val_loss: 4.0446e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 166/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7989e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00166: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.7989e-05 - mean_absolute_error: 0.0075 - val_loss: 2.9095e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 167/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.3192e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00167: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.3192e-05 - mean_absolute_error: 0.0074 - val_loss: 3.3775e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 168/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0238e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00168: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.0238e-04 - mean_absolute_error: 0.0082 - val_loss: 4.3800e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 169/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.8360e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00169: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 8.8360e-05 - mean_absolute_error: 0.0077 - val_loss: 7.9057e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 170/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0741e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00170: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 120ms/step - loss: 1.0741e-04 - mean_absolute_error: 0.0084 - val_loss: 2.0326e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 171/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.3966e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00171: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 9.3966e-05 - mean_absolute_error: 0.0080 - val_loss: 5.6794e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 172/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0665e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00172: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 1.0665e-04 - mean_absolute_error: 0.0082 - val_loss: 3.8496e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 173/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.0932e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00173: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 9.0932e-05 - mean_absolute_error: 0.0079 - val_loss: 2.7989e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 174/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0908e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00174: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 1.0908e-04 - mean_absolute_error: 0.0083 - val_loss: 2.7142e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 175/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2303e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00175: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.2303e-05 - mean_absolute_error: 0.0075 - val_loss: 2.0120e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 176/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.3847e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00176: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.3847e-05 - mean_absolute_error: 0.0077 - val_loss: 1.8742e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 177/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0253e-04 - mean_absolute_error: 0.0080\n",
            "Epoch 00177: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0253e-04 - mean_absolute_error: 0.0080 - val_loss: 2.5760e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 178/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.7846e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00178: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 123ms/step - loss: 9.7846e-05 - mean_absolute_error: 0.0081 - val_loss: 2.5807e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 179/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7738e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00179: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 125ms/step - loss: 8.7738e-05 - mean_absolute_error: 0.0078 - val_loss: 1.5972e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 180/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.8904e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00180: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.8904e-05 - mean_absolute_error: 0.0077 - val_loss: 1.1369e-04 - val_mean_absolute_error: 0.0087\n",
            "Epoch 181/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.2503e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00181: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 9.2503e-05 - mean_absolute_error: 0.0080 - val_loss: 3.8403e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 182/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.5650e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00182: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 9.5650e-05 - mean_absolute_error: 0.0079 - val_loss: 1.7350e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 183/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.8944e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00183: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 8.8944e-05 - mean_absolute_error: 0.0076 - val_loss: 2.7290e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 184/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.9035e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00184: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.9035e-05 - mean_absolute_error: 0.0077 - val_loss: 2.5344e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 185/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7791e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00185: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.7791e-05 - mean_absolute_error: 0.0075 - val_loss: 2.3983e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 186/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0654e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00186: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 1.0654e-04 - mean_absolute_error: 0.0082 - val_loss: 3.7824e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 187/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7586e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00187: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.7586e-05 - mean_absolute_error: 0.0076 - val_loss: 2.3976e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 188/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2913e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00188: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.2913e-05 - mean_absolute_error: 0.0075 - val_loss: 3.4095e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 189/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6500e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00189: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.6500e-05 - mean_absolute_error: 0.0077 - val_loss: 5.6218e-05 - val_mean_absolute_error: 0.0073\n",
            "Epoch 190/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6394e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00190: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.6394e-05 - mean_absolute_error: 0.0076 - val_loss: 4.1098e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 191/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0978e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00191: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 1.0978e-04 - mean_absolute_error: 0.0085 - val_loss: 4.8045e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 192/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.9236e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00192: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.9236e-05 - mean_absolute_error: 0.0077 - val_loss: 2.8773e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 193/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.8894e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00193: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 8.8894e-05 - mean_absolute_error: 0.0078 - val_loss: 1.0379e-04 - val_mean_absolute_error: 0.0067\n",
            "Epoch 194/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.5736e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00194: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.5736e-05 - mean_absolute_error: 0.0076 - val_loss: 1.9803e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 195/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.5350e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00195: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.5350e-05 - mean_absolute_error: 0.0075 - val_loss: 2.1575e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 196/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.0001e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00196: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 9.0001e-05 - mean_absolute_error: 0.0079 - val_loss: 2.8717e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 197/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2335e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00197: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 8.2335e-05 - mean_absolute_error: 0.0075 - val_loss: 1.7609e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 198/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.4345e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00198: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 8.4345e-05 - mean_absolute_error: 0.0076 - val_loss: 3.3164e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 199/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.5225e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00199: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 8.5225e-05 - mean_absolute_error: 0.0077 - val_loss: 2.2738e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 200/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.5773e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00200: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 7.5773e-05 - mean_absolute_error: 0.0072 - val_loss: 1.7055e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 201/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8334e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00201: val_loss did not improve from 0.00002\n",
            "124/124 [==============================] - 16s 128ms/step - loss: 7.8334e-05 - mean_absolute_error: 0.0072 - val_loss: 5.6456e-05 - val_mean_absolute_error: 0.0081\n",
            "Epoch 202/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.2812e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00202: val_loss improved from 0.00002 to 0.00001, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 121ms/step - loss: 9.2812e-05 - mean_absolute_error: 0.0077 - val_loss: 1.4071e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 203/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.4220e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00203: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.4220e-05 - mean_absolute_error: 0.0076 - val_loss: 4.3459e-05 - val_mean_absolute_error: 0.0067\n",
            "Epoch 204/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7306e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00204: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.7306e-05 - mean_absolute_error: 0.0078 - val_loss: 3.4176e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 205/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.1628e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00205: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.1628e-05 - mean_absolute_error: 0.0075 - val_loss: 3.3593e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 206/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6516e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00206: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.6516e-05 - mean_absolute_error: 0.0074 - val_loss: 3.7178e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 207/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.5190e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00207: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.5190e-05 - mean_absolute_error: 0.0079 - val_loss: 5.4620e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 208/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0083e-04 - mean_absolute_error: 0.0080\n",
            "Epoch 00208: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 1.0083e-04 - mean_absolute_error: 0.0080 - val_loss: 7.8586e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 209/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.7309e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00209: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 9.7309e-05 - mean_absolute_error: 0.0080 - val_loss: 1.7011e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 210/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.1809e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00210: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 8.1809e-05 - mean_absolute_error: 0.0073 - val_loss: 2.5502e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 211/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6977e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00211: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.6977e-05 - mean_absolute_error: 0.0071 - val_loss: 3.3616e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 212/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.3975e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00212: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.3975e-05 - mean_absolute_error: 0.0079 - val_loss: 2.8371e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 213/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.0867e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00213: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.0867e-05 - mean_absolute_error: 0.0073 - val_loss: 6.9091e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 214/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.1651e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00214: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.1651e-05 - mean_absolute_error: 0.0077 - val_loss: 2.2156e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 215/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.4760e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00215: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 8.4760e-05 - mean_absolute_error: 0.0076 - val_loss: 4.0921e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 216/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6814e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00216: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.6814e-05 - mean_absolute_error: 0.0077 - val_loss: 2.1994e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 217/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9157e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00217: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.9157e-05 - mean_absolute_error: 0.0074 - val_loss: 3.3501e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 218/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7854e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00218: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.7854e-05 - mean_absolute_error: 0.0077 - val_loss: 1.5266e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 219/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.9395e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00219: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 8.9395e-05 - mean_absolute_error: 0.0077 - val_loss: 3.7738e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 220/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.1558e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00220: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 9.1558e-05 - mean_absolute_error: 0.0078 - val_loss: 2.3445e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 221/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9338e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00221: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 7.9338e-05 - mean_absolute_error: 0.0073 - val_loss: 3.4500e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 222/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3035e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00222: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.3035e-05 - mean_absolute_error: 0.0071 - val_loss: 3.6066e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 223/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9873e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00223: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 122ms/step - loss: 7.9873e-05 - mean_absolute_error: 0.0075 - val_loss: 2.7870e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 224/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.3457e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00224: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.3457e-05 - mean_absolute_error: 0.0074 - val_loss: 2.7681e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 225/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7868e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00225: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.7868e-05 - mean_absolute_error: 0.0074 - val_loss: 2.9577e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 226/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9315e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00226: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 120ms/step - loss: 7.9315e-05 - mean_absolute_error: 0.0072 - val_loss: 2.3287e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 227/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2994e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00227: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.2994e-05 - mean_absolute_error: 0.0075 - val_loss: 1.5819e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 228/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8216e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00228: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.8216e-05 - mean_absolute_error: 0.0069 - val_loss: 2.4802e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 229/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.2251e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00229: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.2251e-05 - mean_absolute_error: 0.0077 - val_loss: 1.9602e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 230/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2418e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00230: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.2418e-05 - mean_absolute_error: 0.0074 - val_loss: 2.4142e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 231/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6215e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00231: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.6215e-05 - mean_absolute_error: 0.0075 - val_loss: 3.2991e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 232/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.3551e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00232: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.3551e-05 - mean_absolute_error: 0.0074 - val_loss: 1.5826e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 233/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8998e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00233: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.8998e-05 - mean_absolute_error: 0.0073 - val_loss: 2.2906e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 234/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8901e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00234: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.8901e-05 - mean_absolute_error: 0.0073 - val_loss: 2.1056e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 235/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.0644e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00235: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 8.0644e-05 - mean_absolute_error: 0.0073 - val_loss: 2.1244e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 236/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 1.0167e-04 - mean_absolute_error: 0.0078\n",
            "Epoch 00236: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 1.0167e-04 - mean_absolute_error: 0.0078 - val_loss: 8.5197e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 237/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.9871e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00237: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 8.9871e-05 - mean_absolute_error: 0.0077 - val_loss: 5.2976e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 238/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.6081e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00238: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 9.6081e-05 - mean_absolute_error: 0.0077 - val_loss: 3.2982e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 239/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7373e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00239: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.7373e-05 - mean_absolute_error: 0.0076 - val_loss: 2.4267e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 240/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.4777e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00240: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.4777e-05 - mean_absolute_error: 0.0071 - val_loss: 1.6193e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 241/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0822e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00241: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.0822e-05 - mean_absolute_error: 0.0071 - val_loss: 1.8481e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 242/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.5683e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00242: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.5683e-05 - mean_absolute_error: 0.0073 - val_loss: 1.5539e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 243/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.6820e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00243: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 9.6820e-05 - mean_absolute_error: 0.0081 - val_loss: 1.6637e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 244/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2164e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00244: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.2164e-05 - mean_absolute_error: 0.0074 - val_loss: 8.0365e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 245/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2024e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00245: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 8.2024e-05 - mean_absolute_error: 0.0073 - val_loss: 3.9845e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 246/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7209e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00246: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.7209e-05 - mean_absolute_error: 0.0072 - val_loss: 3.8095e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 247/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9138e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00247: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 7.9138e-05 - mean_absolute_error: 0.0074 - val_loss: 2.8371e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 248/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9746e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00248: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.9746e-05 - mean_absolute_error: 0.0074 - val_loss: 1.5873e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 249/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8852e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00249: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.8852e-05 - mean_absolute_error: 0.0073 - val_loss: 2.7990e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 250/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8033e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00250: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.8033e-05 - mean_absolute_error: 0.0074 - val_loss: 3.5917e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 251/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.0801e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00251: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 9.0801e-05 - mean_absolute_error: 0.0075 - val_loss: 1.6213e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 252/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6952e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00252: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.6952e-05 - mean_absolute_error: 0.0071 - val_loss: 2.1610e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 253/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0204e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00253: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.0204e-05 - mean_absolute_error: 0.0069 - val_loss: 5.4456e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 254/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2230e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00254: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.2230e-05 - mean_absolute_error: 0.0070 - val_loss: 1.8068e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 255/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.5702e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00255: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 8.5702e-05 - mean_absolute_error: 0.0076 - val_loss: 3.0521e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 256/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.0562e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00256: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 8.0562e-05 - mean_absolute_error: 0.0074 - val_loss: 2.7406e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 257/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.1108e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00257: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.1108e-05 - mean_absolute_error: 0.0074 - val_loss: 3.8572e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 258/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2515e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00258: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 8.2515e-05 - mean_absolute_error: 0.0075 - val_loss: 1.5992e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 259/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.3819e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00259: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.3819e-05 - mean_absolute_error: 0.0073 - val_loss: 4.1607e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 260/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7509e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00260: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.7509e-05 - mean_absolute_error: 0.0075 - val_loss: 2.0850e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 261/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.0564e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00261: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 9.0564e-05 - mean_absolute_error: 0.0077 - val_loss: 3.0439e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 262/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8913e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00262: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.8913e-05 - mean_absolute_error: 0.0071 - val_loss: 2.2823e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 263/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7479e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00263: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.7479e-05 - mean_absolute_error: 0.0071 - val_loss: 3.8821e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 264/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8314e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00264: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.8314e-05 - mean_absolute_error: 0.0072 - val_loss: 1.7965e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 265/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8099e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00265: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.8099e-05 - mean_absolute_error: 0.0074 - val_loss: 2.7620e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 266/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.1834e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00266: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 8.1834e-05 - mean_absolute_error: 0.0074 - val_loss: 1.8927e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 267/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.0980e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00267: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 124ms/step - loss: 8.0980e-05 - mean_absolute_error: 0.0072 - val_loss: 1.5960e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 268/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7079e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00268: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.7079e-05 - mean_absolute_error: 0.0074 - val_loss: 1.7655e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 269/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8490e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00269: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 7.8490e-05 - mean_absolute_error: 0.0072 - val_loss: 2.2284e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 270/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.4656e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00270: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 8.4656e-05 - mean_absolute_error: 0.0074 - val_loss: 2.9994e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 271/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.5131e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00271: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.5131e-05 - mean_absolute_error: 0.0071 - val_loss: 1.3946e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 272/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3231e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00272: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.3231e-05 - mean_absolute_error: 0.0070 - val_loss: 1.9554e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 273/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8048e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00273: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 7.8048e-05 - mean_absolute_error: 0.0073 - val_loss: 3.1847e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 274/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6758e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00274: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.6758e-05 - mean_absolute_error: 0.0075 - val_loss: 2.0412e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 275/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2508e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00275: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.2508e-05 - mean_absolute_error: 0.0073 - val_loss: 3.6692e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 276/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.0114e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00276: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.0114e-05 - mean_absolute_error: 0.0074 - val_loss: 2.8183e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 277/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7429e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00277: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.7429e-05 - mean_absolute_error: 0.0072 - val_loss: 2.1400e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 278/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3459e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00278: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.3459e-05 - mean_absolute_error: 0.0069 - val_loss: 5.1696e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 279/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.1662e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00279: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.1662e-05 - mean_absolute_error: 0.0073 - val_loss: 1.7308e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 280/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6652e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00280: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.6652e-05 - mean_absolute_error: 0.0072 - val_loss: 4.6262e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 281/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.8485e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00281: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.8485e-05 - mean_absolute_error: 0.0075 - val_loss: 3.0366e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 282/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2783e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00282: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 7.2783e-05 - mean_absolute_error: 0.0070 - val_loss: 5.2553e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 283/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6367e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00283: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.6367e-05 - mean_absolute_error: 0.0076 - val_loss: 3.0003e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 284/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9661e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00284: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 6.9661e-05 - mean_absolute_error: 0.0070 - val_loss: 2.5311e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 285/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.0050e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00285: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 8.0050e-05 - mean_absolute_error: 0.0072 - val_loss: 1.8690e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 286/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7175e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00286: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 8.7175e-05 - mean_absolute_error: 0.0074 - val_loss: 3.0996e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 287/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9359e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00287: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.9359e-05 - mean_absolute_error: 0.0074 - val_loss: 1.9274e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 288/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9343e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00288: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 117ms/step - loss: 7.9343e-05 - mean_absolute_error: 0.0072 - val_loss: 2.6593e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 289/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8636e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00289: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 15s 125ms/step - loss: 6.8636e-05 - mean_absolute_error: 0.0070 - val_loss: 1.3383e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 290/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 9.0991e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00290: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 16s 130ms/step - loss: 9.0991e-05 - mean_absolute_error: 0.0076 - val_loss: 2.5044e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 291/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8455e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00291: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.8455e-05 - mean_absolute_error: 0.0073 - val_loss: 5.5556e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 292/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7095e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00292: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.7095e-05 - mean_absolute_error: 0.0072 - val_loss: 4.0302e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 293/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8350e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00293: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.8350e-05 - mean_absolute_error: 0.0070 - val_loss: 2.1572e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 294/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6215e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00294: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.6215e-05 - mean_absolute_error: 0.0072 - val_loss: 1.7457e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 295/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3372e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00295: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.3372e-05 - mean_absolute_error: 0.0069 - val_loss: 2.5826e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 296/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2844e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00296: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.2844e-05 - mean_absolute_error: 0.0071 - val_loss: 2.0553e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 297/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2793e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00297: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 8.2793e-05 - mean_absolute_error: 0.0074 - val_loss: 3.1947e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 298/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7435e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00298: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 8.7435e-05 - mean_absolute_error: 0.0075 - val_loss: 5.2537e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 299/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6997e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00299: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.6997e-05 - mean_absolute_error: 0.0070 - val_loss: 2.3968e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 300/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9456e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00300: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.9456e-05 - mean_absolute_error: 0.0072 - val_loss: 2.2737e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 301/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7496e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00301: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.7496e-05 - mean_absolute_error: 0.0071 - val_loss: 4.4303e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 302/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2610e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00302: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.2610e-05 - mean_absolute_error: 0.0070 - val_loss: 2.9562e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 303/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.1717e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00303: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 8.1717e-05 - mean_absolute_error: 0.0074 - val_loss: 2.8744e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 304/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7911e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00304: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.7911e-05 - mean_absolute_error: 0.0073 - val_loss: 2.7346e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 305/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0362e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00305: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.0362e-05 - mean_absolute_error: 0.0068 - val_loss: 2.6287e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 306/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6959e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00306: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.6959e-05 - mean_absolute_error: 0.0072 - val_loss: 1.2853e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 307/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3767e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00307: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.3767e-05 - mean_absolute_error: 0.0071 - val_loss: 1.5987e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 308/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.4650e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00308: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.4650e-05 - mean_absolute_error: 0.0066 - val_loss: 2.1879e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 309/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1522e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00309: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.1522e-05 - mean_absolute_error: 0.0069 - val_loss: 1.8454e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 310/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1230e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00310: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.1230e-05 - mean_absolute_error: 0.0069 - val_loss: 1.4340e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 311/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2908e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00311: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 125ms/step - loss: 7.2908e-05 - mean_absolute_error: 0.0070 - val_loss: 1.6064e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 312/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9936e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00312: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 119ms/step - loss: 6.9936e-05 - mean_absolute_error: 0.0069 - val_loss: 3.7224e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 313/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8636e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00313: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.8636e-05 - mean_absolute_error: 0.0072 - val_loss: 2.0988e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 314/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8506e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00314: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.8506e-05 - mean_absolute_error: 0.0071 - val_loss: 2.5316e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 315/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.4796e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00315: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.4796e-05 - mean_absolute_error: 0.0070 - val_loss: 1.4733e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 316/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2041e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00316: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.2041e-05 - mean_absolute_error: 0.0069 - val_loss: 1.6317e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 317/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8398e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00317: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.8398e-05 - mean_absolute_error: 0.0069 - val_loss: 1.5114e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 318/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9980e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00318: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.9980e-05 - mean_absolute_error: 0.0068 - val_loss: 1.2694e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 319/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1595e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00319: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.1595e-05 - mean_absolute_error: 0.0067 - val_loss: 2.2952e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 320/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8689e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00320: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.8689e-05 - mean_absolute_error: 0.0068 - val_loss: 2.3763e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 321/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2480e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00321: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.2480e-05 - mean_absolute_error: 0.0068 - val_loss: 1.6215e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 322/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0825e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00322: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.0825e-05 - mean_absolute_error: 0.0068 - val_loss: 1.4933e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 323/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9502e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00323: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.9502e-05 - mean_absolute_error: 0.0072 - val_loss: 3.0765e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 324/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2642e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00324: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.2642e-05 - mean_absolute_error: 0.0070 - val_loss: 1.3256e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 325/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0647e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00325: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.0647e-05 - mean_absolute_error: 0.0068 - val_loss: 2.2425e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 326/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2317e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00326: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.2317e-05 - mean_absolute_error: 0.0071 - val_loss: 2.0022e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 327/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9523e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00327: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.9523e-05 - mean_absolute_error: 0.0068 - val_loss: 4.8825e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 328/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.6621e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00328: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 8.6621e-05 - mean_absolute_error: 0.0075 - val_loss: 1.9711e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 329/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.4397e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00329: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 8.4397e-05 - mean_absolute_error: 0.0075 - val_loss: 8.0846e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 330/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.5940e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00330: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.5940e-05 - mean_absolute_error: 0.0069 - val_loss: 1.4768e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 331/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.7272e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00331: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 6.7272e-05 - mean_absolute_error: 0.0068 - val_loss: 2.0435e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 332/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7500e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00332: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.7500e-05 - mean_absolute_error: 0.0071 - val_loss: 4.8233e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 333/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2885e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00333: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 16s 126ms/step - loss: 8.2885e-05 - mean_absolute_error: 0.0072 - val_loss: 1.6845e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 334/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8760e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00334: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.8760e-05 - mean_absolute_error: 0.0071 - val_loss: 1.6510e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 335/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9843e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00335: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 6.9843e-05 - mean_absolute_error: 0.0067 - val_loss: 2.7044e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 336/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.7526e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00336: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 6.7526e-05 - mean_absolute_error: 0.0068 - val_loss: 1.5652e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 337/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8054e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00337: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.8054e-05 - mean_absolute_error: 0.0070 - val_loss: 2.3452e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 338/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.5685e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00338: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 111ms/step - loss: 7.5685e-05 - mean_absolute_error: 0.0070 - val_loss: 3.2909e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 339/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.3423e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00339: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 8.3423e-05 - mean_absolute_error: 0.0075 - val_loss: 2.5299e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 340/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1673e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00340: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.1673e-05 - mean_absolute_error: 0.0069 - val_loss: 1.7261e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 341/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6310e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00341: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.6310e-05 - mean_absolute_error: 0.0070 - val_loss: 1.3675e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 342/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6282e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00342: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.6282e-05 - mean_absolute_error: 0.0071 - val_loss: 2.4621e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 343/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7001e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00343: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.7001e-05 - mean_absolute_error: 0.0071 - val_loss: 4.2806e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 344/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9798e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00344: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.9798e-05 - mean_absolute_error: 0.0074 - val_loss: 2.2832e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 345/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9719e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00345: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.9719e-05 - mean_absolute_error: 0.0071 - val_loss: 1.5541e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 346/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8881e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00346: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.8881e-05 - mean_absolute_error: 0.0069 - val_loss: 2.4599e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 347/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3012e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00347: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.3012e-05 - mean_absolute_error: 0.0070 - val_loss: 3.7486e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 348/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.7858e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00348: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.7858e-05 - mean_absolute_error: 0.0068 - val_loss: 1.9357e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 349/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.5243e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00349: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.5243e-05 - mean_absolute_error: 0.0067 - val_loss: 2.3527e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 350/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2552e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00350: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.2552e-05 - mean_absolute_error: 0.0069 - val_loss: 1.4447e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 351/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.4588e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00351: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.4588e-05 - mean_absolute_error: 0.0070 - val_loss: 3.3106e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 352/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9428e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00352: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.9428e-05 - mean_absolute_error: 0.0072 - val_loss: 1.2941e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 353/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2715e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00353: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.2715e-05 - mean_absolute_error: 0.0069 - val_loss: 1.6689e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 354/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1076e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00354: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.1076e-05 - mean_absolute_error: 0.0070 - val_loss: 1.8983e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 355/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8515e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00355: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 17s 135ms/step - loss: 6.8515e-05 - mean_absolute_error: 0.0068 - val_loss: 3.1831e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 356/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8138e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00356: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 6.8138e-05 - mean_absolute_error: 0.0067 - val_loss: 3.2900e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 357/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0472e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00357: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.0472e-05 - mean_absolute_error: 0.0068 - val_loss: 1.3847e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 358/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3722e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00358: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 111ms/step - loss: 7.3722e-05 - mean_absolute_error: 0.0069 - val_loss: 1.8853e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 359/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2041e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00359: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 111ms/step - loss: 7.2041e-05 - mean_absolute_error: 0.0068 - val_loss: 2.7495e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 360/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2456e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00360: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.2456e-05 - mean_absolute_error: 0.0070 - val_loss: 1.3926e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 361/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.3121e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00361: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.3121e-05 - mean_absolute_error: 0.0066 - val_loss: 1.6877e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 362/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3550e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00362: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.3550e-05 - mean_absolute_error: 0.0071 - val_loss: 2.0720e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 363/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.1684e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00363: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 8.1684e-05 - mean_absolute_error: 0.0071 - val_loss: 1.8124e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 364/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9797e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00364: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.9797e-05 - mean_absolute_error: 0.0074 - val_loss: 1.5331e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 365/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.4024e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00365: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 6.4024e-05 - mean_absolute_error: 0.0067 - val_loss: 2.6950e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 366/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.0119e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00366: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 8.0119e-05 - mean_absolute_error: 0.0072 - val_loss: 1.5642e-05 - val_mean_absolute_error: 0.0022\n",
            "Epoch 367/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.5485e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00367: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.5485e-05 - mean_absolute_error: 0.0069 - val_loss: 1.4387e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 368/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8876e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00368: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 6.8876e-05 - mean_absolute_error: 0.0067 - val_loss: 1.9602e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 369/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.5785e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00369: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.5785e-05 - mean_absolute_error: 0.0066 - val_loss: 1.5447e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 370/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9401e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00370: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.9401e-05 - mean_absolute_error: 0.0068 - val_loss: 1.9219e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 371/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8953e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00371: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.8953e-05 - mean_absolute_error: 0.0073 - val_loss: 1.7000e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 372/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.5472e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00372: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.5472e-05 - mean_absolute_error: 0.0069 - val_loss: 1.7732e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 373/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6282e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00373: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.6282e-05 - mean_absolute_error: 0.0070 - val_loss: 1.2620e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 374/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.8924e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00374: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.8924e-05 - mean_absolute_error: 0.0072 - val_loss: 3.0741e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 375/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2703e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00375: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.2703e-05 - mean_absolute_error: 0.0070 - val_loss: 1.8471e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 376/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.7554e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00376: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 6.7554e-05 - mean_absolute_error: 0.0067 - val_loss: 2.6672e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 377/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7901e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00377: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 7.7901e-05 - mean_absolute_error: 0.0071 - val_loss: 4.0857e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 378/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.6634e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00378: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 120ms/step - loss: 6.6634e-05 - mean_absolute_error: 0.0067 - val_loss: 1.3772e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 379/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.4085e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00379: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.4085e-05 - mean_absolute_error: 0.0069 - val_loss: 2.4100e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 380/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.4342e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00380: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 6.4342e-05 - mean_absolute_error: 0.0068 - val_loss: 3.6589e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 381/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.4524e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00381: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.4524e-05 - mean_absolute_error: 0.0071 - val_loss: 8.3787e-05 - val_mean_absolute_error: 0.0067\n",
            "Epoch 382/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.0654e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00382: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 8.0654e-05 - mean_absolute_error: 0.0072 - val_loss: 2.5889e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 383/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.6954e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00383: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.6954e-05 - mean_absolute_error: 0.0068 - val_loss: 2.3889e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 384/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.7266e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00384: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.7266e-05 - mean_absolute_error: 0.0067 - val_loss: 1.7677e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 385/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0090e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00385: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.0090e-05 - mean_absolute_error: 0.0069 - val_loss: 1.3766e-05 - val_mean_absolute_error: 0.0021\n",
            "Epoch 386/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2485e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00386: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.2485e-05 - mean_absolute_error: 0.0069 - val_loss: 1.6278e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 387/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2641e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00387: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.2641e-05 - mean_absolute_error: 0.0068 - val_loss: 3.1841e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 388/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.7529e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00388: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 6.7529e-05 - mean_absolute_error: 0.0068 - val_loss: 3.9688e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 389/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.6582e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00389: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.6582e-05 - mean_absolute_error: 0.0071 - val_loss: 5.0796e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 390/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.7342e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00390: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.7342e-05 - mean_absolute_error: 0.0068 - val_loss: 2.3122e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 391/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8571e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00391: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.8571e-05 - mean_absolute_error: 0.0067 - val_loss: 1.7103e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 392/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9915e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00392: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.9915e-05 - mean_absolute_error: 0.0072 - val_loss: 3.7197e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 393/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9332e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00393: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.9332e-05 - mean_absolute_error: 0.0068 - val_loss: 3.0373e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 394/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1716e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00394: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.1716e-05 - mean_absolute_error: 0.0068 - val_loss: 1.2993e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 395/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.4812e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00395: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.4812e-05 - mean_absolute_error: 0.0069 - val_loss: 1.7861e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 396/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1780e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00396: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.1780e-05 - mean_absolute_error: 0.0069 - val_loss: 1.8350e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 397/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.6361e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00397: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.6361e-05 - mean_absolute_error: 0.0066 - val_loss: 1.6294e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 398/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.5940e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00398: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 6.5940e-05 - mean_absolute_error: 0.0068 - val_loss: 1.5008e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 399/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3430e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00399: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 7.3430e-05 - mean_absolute_error: 0.0070 - val_loss: 2.5023e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 400/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0151e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00400: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.0151e-05 - mean_absolute_error: 0.0068 - val_loss: 4.3132e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 401/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.9110e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00401: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 121ms/step - loss: 7.9110e-05 - mean_absolute_error: 0.0072 - val_loss: 1.7726e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 402/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8172e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00402: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.8172e-05 - mean_absolute_error: 0.0068 - val_loss: 1.5453e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 403/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 5.9274e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00403: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 5.9274e-05 - mean_absolute_error: 0.0065 - val_loss: 1.8269e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 404/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3327e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00404: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.3327e-05 - mean_absolute_error: 0.0070 - val_loss: 2.0491e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 405/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.7033e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00405: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.7033e-05 - mean_absolute_error: 0.0067 - val_loss: 3.0160e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 406/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.5571e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00406: val_loss improved from 0.00001 to 0.00001, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-1-layers-3-units-256.h5\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 6.5571e-05 - mean_absolute_error: 0.0067 - val_loss: 1.2367e-05 - val_mean_absolute_error: 0.0021\n",
            "Epoch 407/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2768e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00407: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.2768e-05 - mean_absolute_error: 0.0067 - val_loss: 2.6305e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 408/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.2544e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00408: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.2544e-05 - mean_absolute_error: 0.0064 - val_loss: 1.3516e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 409/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.4097e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00409: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.4097e-05 - mean_absolute_error: 0.0065 - val_loss: 2.1679e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 410/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8250e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00410: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.8250e-05 - mean_absolute_error: 0.0068 - val_loss: 3.6580e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 411/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1638e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00411: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.1638e-05 - mean_absolute_error: 0.0069 - val_loss: 1.2784e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 412/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.1843e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00412: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.1843e-05 - mean_absolute_error: 0.0066 - val_loss: 3.4552e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 413/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.7468e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00413: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 8.7468e-05 - mean_absolute_error: 0.0074 - val_loss: 7.1934e-05 - val_mean_absolute_error: 0.0072\n",
            "Epoch 414/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3688e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00414: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 111ms/step - loss: 7.3688e-05 - mean_absolute_error: 0.0070 - val_loss: 2.2492e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 415/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8099e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00415: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 6.8099e-05 - mean_absolute_error: 0.0068 - val_loss: 1.8276e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 416/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2010e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00416: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 7.2010e-05 - mean_absolute_error: 0.0068 - val_loss: 1.2999e-05 - val_mean_absolute_error: 0.0021\n",
            "Epoch 417/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.5928e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00417: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 111ms/step - loss: 6.5928e-05 - mean_absolute_error: 0.0067 - val_loss: 1.4581e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 418/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.0969e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00418: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 110ms/step - loss: 6.0969e-05 - mean_absolute_error: 0.0066 - val_loss: 1.3908e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 419/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.4613e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00419: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 110ms/step - loss: 6.4613e-05 - mean_absolute_error: 0.0066 - val_loss: 1.4133e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 420/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0613e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00420: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 7.0613e-05 - mean_absolute_error: 0.0068 - val_loss: 2.0362e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 421/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.6930e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00421: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 111ms/step - loss: 6.6930e-05 - mean_absolute_error: 0.0065 - val_loss: 2.6048e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 422/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3005e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00422: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 7.3005e-05 - mean_absolute_error: 0.0070 - val_loss: 1.4121e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 423/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8100e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00423: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 6.8100e-05 - mean_absolute_error: 0.0068 - val_loss: 3.2065e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 424/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.1319e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00424: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 8.1319e-05 - mean_absolute_error: 0.0072 - val_loss: 2.7424e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 425/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.6026e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00425: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.6026e-05 - mean_absolute_error: 0.0066 - val_loss: 2.3197e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 426/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.2884e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00426: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.2884e-05 - mean_absolute_error: 0.0069 - val_loss: 2.6274e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 427/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9949e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00427: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.9949e-05 - mean_absolute_error: 0.0068 - val_loss: 1.5418e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 428/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.6355e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00428: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.6355e-05 - mean_absolute_error: 0.0067 - val_loss: 2.6114e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 429/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.8647e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00429: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 115ms/step - loss: 6.8647e-05 - mean_absolute_error: 0.0069 - val_loss: 1.6526e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 430/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3281e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00430: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.3281e-05 - mean_absolute_error: 0.0070 - val_loss: 2.3512e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 431/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9074e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00431: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 6.9074e-05 - mean_absolute_error: 0.0067 - val_loss: 2.2557e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 432/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0147e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00432: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.0147e-05 - mean_absolute_error: 0.0068 - val_loss: 4.8791e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 433/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.7740e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00433: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.7740e-05 - mean_absolute_error: 0.0070 - val_loss: 2.5056e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 434/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.2533e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00434: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.2533e-05 - mean_absolute_error: 0.0065 - val_loss: 2.9259e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 435/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9312e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00435: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 113ms/step - loss: 6.9312e-05 - mean_absolute_error: 0.0068 - val_loss: 1.9551e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 436/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9486e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00436: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.9486e-05 - mean_absolute_error: 0.0068 - val_loss: 6.7712e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 437/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.5233e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00437: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.5233e-05 - mean_absolute_error: 0.0070 - val_loss: 1.4744e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 438/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.0342e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00438: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.0342e-05 - mean_absolute_error: 0.0065 - val_loss: 1.9609e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 439/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.9096e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00439: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 6.9096e-05 - mean_absolute_error: 0.0068 - val_loss: 1.6647e-05 - val_mean_absolute_error: 0.0026\n",
            "Epoch 440/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 8.2003e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00440: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 8.2003e-05 - mean_absolute_error: 0.0072 - val_loss: 1.4636e-05 - val_mean_absolute_error: 0.0028\n",
            "Epoch 441/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.5423e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00441: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 116ms/step - loss: 7.5423e-05 - mean_absolute_error: 0.0067 - val_loss: 1.6405e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 442/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.2640e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00442: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 118ms/step - loss: 6.2640e-05 - mean_absolute_error: 0.0066 - val_loss: 1.5189e-05 - val_mean_absolute_error: 0.0025\n",
            "Epoch 443/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.3122e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00443: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 112ms/step - loss: 6.3122e-05 - mean_absolute_error: 0.0065 - val_loss: 1.7360e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 444/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.0920e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00444: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 15s 117ms/step - loss: 7.0920e-05 - mean_absolute_error: 0.0068 - val_loss: 2.3379e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 445/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 6.2527e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00445: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 16s 125ms/step - loss: 6.2527e-05 - mean_absolute_error: 0.0066 - val_loss: 1.5749e-05 - val_mean_absolute_error: 0.0024\n",
            "Epoch 446/500\n",
            "124/124 [==============================] - ETA: 0s - loss: 7.3591e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00446: val_loss did not improve from 0.00001\n",
            "124/124 [==============================] - 14s 114ms/step - loss: 7.3591e-05 - mean_absolute_error: 0.0070 - val_loss: 1.4676e-05 - val_mean_absolute_error: 0.0023\n",
            "Epoch 447/500\n",
            " 37/124 [=======>......................] - ETA: 9s - loss: 5.5986e-05 - mean_absolute_error: 0.0061Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ4KK6MvkRAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff263ee5-a0f3-4703-eed1-42905d67cc05"
      },
      "source": [
        "!ls /content/gdrive/'My Drive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 01_Introduction.ppt\n",
            "'02_Computer Evolution and Performance.ppt'\n",
            "'02 Instruction Level Parallelism DATA FLOW uArch (1).pptx'\n",
            "'02 Instruction Level Parallelism DATA FLOW uArch.pptx'\n",
            "'03_Top Level View of Computer Function and Interconnection.pptx'\n",
            "'04_Cache Memory.pptx'\n",
            "'05_Internal Memory '\n",
            "'06_External Memory'\n",
            " 09_Arithmetic\n",
            "'1-2017 Guide for KGSP at KNU(brochure).pdf'\n",
            "'1-2017 Guide for KGSP at KNU (En).pdf'\n",
            "'1-2017 KGSP Application Forms.docx'\n",
            "'1-2017 KGSP Application Guidelines(K-en).pdf'\n",
            " 1300_math_formulas.pdf\n",
            "'500 Word List of Synonyms and Antonyms.pdf'\n",
            " ACA_aasignment.docx\n",
            "'Algorithm 1 Perceptron (AND OR).pdf'\n",
            " analogy.pdf\n",
            "'Analytical Questions with complete solutions.pdf'\n",
            " ANN_1st.m4a\n",
            " ANN_2nd.m4a\n",
            " ANN_3rd.m4a\n",
            " ANN_4.m4a\n",
            " ANN_5cont.m4a\n",
            " ANN_5.m4a\n",
            " ANN_6.m4a\n",
            " ANN_7.m4a\n",
            "'Artificial Neural Networks Spring 2020'\n",
            "'Assignment 01'\n",
            "'assignment 2.pdf'\n",
            "'assignment 4.pdf'\n",
            " Automata_Theory.pdf\n",
            " bform\n",
            " Book_-_Computer_Organization_and_Interfa.pdf\n",
            "'bscs_1_h_f2013_f2017_q_a_marks (1).gsheet'\n",
            " ch10.pdf\n",
            " ch11.pdf\n",
            " ch12.pdf\n",
            " ch1.pdf\n",
            " ch2.pdf\n",
            " ch3.pdf\n",
            " Classroom\n",
            " Cohen_Chapter_2.docx\n",
            "'Colab Notebooks'\n",
            "'Computer Organization and Architecture 10th - William Stallings.pdf'\n",
            " computer-systems-design-and-architecture.pdf\n",
            " Cormen-Introduction%20To%20Algorithms,%202nd%20Edition.pdf\n",
            " COS201_chapter_4_solution.pdf\n",
            " cs231n_2017_lecture3.pdf\n",
            " CS402_handouts_Updated.pdf\n",
            "'Data Mining Practical Machine Learning Tools and Techniques - WEKA.pdf'\n",
            " desmos-graph.pdf\n",
            "'Digital Image Processing 3rd ed. - R. Gonzalez, R. Woods-ilovepdf-compressed.pdf'\n",
            "'Ecab Documentation.docx'\n",
            "'Ecab Documentation.gdoc'\n",
            " ENGLISHFILE010.pdf\n",
            " fileimplementation-120927060731-phpapp01.pdf\n",
            "'Formula List.pdf'\n",
            "'Full Math Book.pdf'\n",
            "'GAT book by dogar 2016'\n",
            "'GAT Book  Hi Brain Dogar publishers.pdf'\n",
            " glorot11a.pdf\n",
            "'HP The Machine'\n",
            " ILC_Prepositions.pdf\n",
            "'INF70005_SEM 1 2018_Assignment 2.docx'\n",
            " introduction-to-computer-theory-by-cohen-copy.pdf\n",
            "'Is the Brain a Digital Computer - John R. Searle.pdf'\n",
            "'Lecture 01_Introduction to ANN Class.pdf'\n",
            " list-of-prepositions.pdf\n",
            "'LIST OF SYNONYMS AND ANTONYMS.pdf'\n",
            " Master_Math_-_Solving_Word_Problems_-_Brita_Immergut.pdf\n",
            "'Most Beautiful Identity.pdf'\n",
            "\"M.Taimoor's Review.docx\"\n",
            " NTS-Book-for-GAT-General-free-download.pdf\n",
            " NTS-Book-for-GAT-General-.pdf\n",
            " onur-740-fall13-module5.2.1-dataflow-part1.ppt\n",
            " Operating_System_Concepts_9ed.pdf\n",
            "'OS presentation.gsheet'\n",
            " OS_Presentation.pptx\n",
            "'Papers With Code : Search for Artificial general intelligence | Papers With Code'\n",
            " PG_Admission_Schedule_2019.pdf\n",
            " pic\n",
            " pic.gdoc\n",
            "'Pipeline & Hazards'\n",
            " PMcasestudy.docx\n",
            " PMcasestudy.gdoc\n",
            " PrepositionChart.pdf\n",
            " Screenshot.pdf\n",
            " Screenshot.png\n",
            "'ScreenShots and Code.zip'\n",
            "'Screenshots of videos (1-40) '\n",
            "'Senior Project Ideas_Fall2014.pdf'\n",
            "'smart home.docx'\n",
            "'SMART HOME using esp32.docx'\n",
            "'SMART HOME using esp32.pdf'\n",
            " solutions-manual-computer-organization-and-architecture-designing-for-performance-eighth-edition-william-stallings.pdf\n",
            "'Solutions toc fulpdf (1).pdf'\n",
            "'Solutions toc fulpdf.pdf'\n",
            " SPM_ASSignment_2.docx\n",
            " StockPrediction\n",
            " summary.pdf\n",
            " Techniques.pdf\n",
            " The-Morgan-Kaufmann-Series-in-Data-Management-Systems-Jiawei-Han-Micheline-Kamber-Jian-Pei-Data-Mining.-Concepts-and-Techniques-3rd-Edition-Morgan-Kaufmann-2011.pdf\n",
            " The_Official_Guide_to_the_GRE_Revised_General_Te.pdf\n",
            " Thoery_of_Automata_CS402.pdf\n",
            "'toc full solutions .pdf'\n",
            "'uetfeechallan (1).aspx'\n",
            " uetfeechallan.aspx\n",
            " uetform.aspx\n",
            " UHS_MDCAT_2019_1970658_Roll_No_Slip.pdf.pdf\n",
            " Untitled\n",
            "'Untitled (1)'\n",
            "'Untitled (2)'\n",
            "'Untitled (3)'\n",
            "'Untitled (4)'\n",
            "'Untitled (5)'\n",
            "'Untitled (6)'\n",
            "'Untitled (7)'\n",
            "'Untitled (8)'\n",
            "'VisualProgramming (1).rar'\n",
            "'VisualProgramming (1).zip'\n",
            "'VisualProgramming (2).zip'\n",
            "'VisualProgramming (3).zip'\n",
            " VisualProgramming.rar\n",
            " VisualProgramming.zip\n",
            " WP_20151104_21_50_03_Pro.jpg\n",
            " zzCAasignmnt.docx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj0Nkz7zkwKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "0ef99070-51bf-4981-b315-dd07e2585093"
      },
      "source": [
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
        "                feature_columns=FEATURE_COLUMNS, shuffle=False)\n",
        "\n",
        "# construct the model\n",
        "#model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                   # dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
        "model.load_weights(model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-037c821f99df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnL70LKTlFH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15c7f480-4764-4b8f-e18c-f6378c4da33e"
      },
      "source": [
        "# evaluate the model\n",
        "mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "# calculate the mean absolute error (inverse scaling)\n",
        "mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 2.5872345891392756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUVOqNB8lNPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, data, classification=False):\n",
        "    # retrieve the last sequence from data\n",
        "    last_sequence = data[\"last_sequence\"][:N_STEPS]\n",
        "    # retrieve the column scalers\n",
        "    column_scaler = data[\"column_scaler\"]\n",
        "    # reshape the last sequence\n",
        "    last_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\n",
        "    # expand dimension\n",
        "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        "    # get the prediction (scaled from 0 to 1)\n",
        "    prediction = model.predict(last_sequence)\n",
        "    # get the price (by inverting the scaling)\n",
        "    predicted_price = column_scaler[\"adjclose\"].inverse_transform(prediction)[0][0]\n",
        "    return predicted_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4i6AgPalROE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf88ec29-cd58-4bb8-8291-9cfabd9b1743"
      },
      "source": [
        "# predict the future price\n",
        "future_price = predict(model, data)\n",
        "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Future price after 1 days is 368.11$\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YABggO-jlbw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_graph(model, data):\n",
        "    y_test = data[\"y_test\"]\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    # last 200 days, feel free to edit that\n",
        "    plt.plot(y_test[-200:], c='b')\n",
        "    plt.plot(y_pred[-200:], c='r')\n",
        "    plt.xlabel(\"Days\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJv1o-WZlf2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "02c7b5b2-68d2-4b8e-efef-85d56d1eaf9b"
      },
      "source": [
        "plot_graph(model, data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkfEM6T8logg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(model, data):\n",
        "    y_test = data[\"y_test\"]\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    y_pred = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_pred[LOOKUP_STEP:]))\n",
        "    y_test = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_test[LOOKUP_STEP:]))\n",
        "    return accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}